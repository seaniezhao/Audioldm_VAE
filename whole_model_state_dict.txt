Model's state_dict:
logvar 	 torch.Size([1000])
betas 	 torch.Size([1000])
alphas_cumprod 	 torch.Size([1000])
alphas_cumprod_prev 	 torch.Size([1000])
sqrt_alphas_cumprod 	 torch.Size([1000])
sqrt_one_minus_alphas_cumprod 	 torch.Size([1000])
log_one_minus_alphas_cumprod 	 torch.Size([1000])
sqrt_recip_alphas_cumprod 	 torch.Size([1000])
sqrt_recipm1_alphas_cumprod 	 torch.Size([1000])
posterior_variance 	 torch.Size([1000])
posterior_log_variance_clipped 	 torch.Size([1000])
posterior_mean_coef1 	 torch.Size([1000])
posterior_mean_coef2 	 torch.Size([1000])
scale_factor 	 torch.Size([])
clap.model.logit_scale_a 	 torch.Size([])
clap.model.logit_scale_t 	 torch.Size([])
clap.model.audio_branch.spectrogram_extractor.stft.conv_real.weight 	 torch.Size([513, 1, 1024])
clap.model.audio_branch.spectrogram_extractor.stft.conv_imag.weight 	 torch.Size([513, 1, 1024])
clap.model.audio_branch.logmel_extractor.melW 	 torch.Size([513, 64])
clap.model.audio_branch.bn0.weight 	 torch.Size([64])
clap.model.audio_branch.bn0.bias 	 torch.Size([64])
clap.model.audio_branch.bn0.running_mean 	 torch.Size([64])
clap.model.audio_branch.bn0.running_var 	 torch.Size([64])
clap.model.audio_branch.bn0.num_batches_tracked 	 torch.Size([])
clap.model.audio_branch.patch_embed.proj.weight 	 torch.Size([128, 1, 4, 4])
clap.model.audio_branch.patch_embed.proj.bias 	 torch.Size([128])
clap.model.audio_branch.patch_embed.norm.weight 	 torch.Size([128])
clap.model.audio_branch.patch_embed.norm.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.0.norm1.weight 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.0.norm1.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 4])
clap.model.audio_branch.layers.0.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.0.blocks.0.attn.qkv.weight 	 torch.Size([384, 128])
clap.model.audio_branch.layers.0.blocks.0.attn.qkv.bias 	 torch.Size([384])
clap.model.audio_branch.layers.0.blocks.0.attn.proj.weight 	 torch.Size([128, 128])
clap.model.audio_branch.layers.0.blocks.0.attn.proj.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.0.norm2.weight 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.0.norm2.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.0.mlp.fc1.weight 	 torch.Size([512, 128])
clap.model.audio_branch.layers.0.blocks.0.mlp.fc1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.0.blocks.0.mlp.fc2.weight 	 torch.Size([128, 512])
clap.model.audio_branch.layers.0.blocks.0.mlp.fc2.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.1.attn_mask 	 torch.Size([64, 64, 64])
clap.model.audio_branch.layers.0.blocks.1.norm1.weight 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.1.norm1.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 4])
clap.model.audio_branch.layers.0.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.0.blocks.1.attn.qkv.weight 	 torch.Size([384, 128])
clap.model.audio_branch.layers.0.blocks.1.attn.qkv.bias 	 torch.Size([384])
clap.model.audio_branch.layers.0.blocks.1.attn.proj.weight 	 torch.Size([128, 128])
clap.model.audio_branch.layers.0.blocks.1.attn.proj.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.1.norm2.weight 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.1.norm2.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.blocks.1.mlp.fc1.weight 	 torch.Size([512, 128])
clap.model.audio_branch.layers.0.blocks.1.mlp.fc1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.0.blocks.1.mlp.fc2.weight 	 torch.Size([128, 512])
clap.model.audio_branch.layers.0.blocks.1.mlp.fc2.bias 	 torch.Size([128])
clap.model.audio_branch.layers.0.downsample.reduction.weight 	 torch.Size([256, 512])
clap.model.audio_branch.layers.0.downsample.norm.weight 	 torch.Size([512])
clap.model.audio_branch.layers.0.downsample.norm.bias 	 torch.Size([512])
clap.model.audio_branch.layers.1.blocks.0.norm1.weight 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.0.norm1.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 8])
clap.model.audio_branch.layers.1.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.1.blocks.0.attn.qkv.weight 	 torch.Size([768, 256])
clap.model.audio_branch.layers.1.blocks.0.attn.qkv.bias 	 torch.Size([768])
clap.model.audio_branch.layers.1.blocks.0.attn.proj.weight 	 torch.Size([256, 256])
clap.model.audio_branch.layers.1.blocks.0.attn.proj.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.0.norm2.weight 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.0.norm2.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.0.mlp.fc1.weight 	 torch.Size([1024, 256])
clap.model.audio_branch.layers.1.blocks.0.mlp.fc1.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.1.blocks.0.mlp.fc2.weight 	 torch.Size([256, 1024])
clap.model.audio_branch.layers.1.blocks.0.mlp.fc2.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.1.attn_mask 	 torch.Size([16, 64, 64])
clap.model.audio_branch.layers.1.blocks.1.norm1.weight 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.1.norm1.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 8])
clap.model.audio_branch.layers.1.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.1.blocks.1.attn.qkv.weight 	 torch.Size([768, 256])
clap.model.audio_branch.layers.1.blocks.1.attn.qkv.bias 	 torch.Size([768])
clap.model.audio_branch.layers.1.blocks.1.attn.proj.weight 	 torch.Size([256, 256])
clap.model.audio_branch.layers.1.blocks.1.attn.proj.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.1.norm2.weight 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.1.norm2.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.blocks.1.mlp.fc1.weight 	 torch.Size([1024, 256])
clap.model.audio_branch.layers.1.blocks.1.mlp.fc1.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.1.blocks.1.mlp.fc2.weight 	 torch.Size([256, 1024])
clap.model.audio_branch.layers.1.blocks.1.mlp.fc2.bias 	 torch.Size([256])
clap.model.audio_branch.layers.1.downsample.reduction.weight 	 torch.Size([512, 1024])
clap.model.audio_branch.layers.1.downsample.norm.weight 	 torch.Size([1024])
clap.model.audio_branch.layers.1.downsample.norm.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.2.blocks.0.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.0.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.0.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.0.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.0.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.0.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.0.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.0.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.0.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.0.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.0.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.0.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.1.attn_mask 	 torch.Size([4, 64, 64])
clap.model.audio_branch.layers.2.blocks.1.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.1.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.1.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.1.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.1.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.1.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.1.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.1.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.1.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.1.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.1.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.1.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.2.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.2.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.2.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.2.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.2.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.2.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.2.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.2.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.2.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.2.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.2.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.2.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.2.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.2.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.3.attn_mask 	 torch.Size([4, 64, 64])
clap.model.audio_branch.layers.2.blocks.3.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.3.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.3.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.3.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.3.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.3.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.3.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.3.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.3.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.3.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.3.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.3.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.3.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.3.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.4.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.4.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.4.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.4.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.4.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.4.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.4.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.4.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.4.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.4.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.4.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.4.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.4.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.4.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.5.attn_mask 	 torch.Size([4, 64, 64])
clap.model.audio_branch.layers.2.blocks.5.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.5.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.5.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.5.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.5.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.5.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.5.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.5.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.5.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.5.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.5.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.5.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.5.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.5.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.6.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.6.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.6.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.6.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.6.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.6.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.6.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.6.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.6.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.6.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.6.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.6.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.6.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.6.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.7.attn_mask 	 torch.Size([4, 64, 64])
clap.model.audio_branch.layers.2.blocks.7.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.7.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.7.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.7.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.7.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.7.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.7.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.7.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.7.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.7.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.7.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.7.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.7.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.7.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.8.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.8.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.8.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.8.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.8.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.8.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.8.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.8.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.8.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.8.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.8.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.8.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.8.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.8.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.9.attn_mask 	 torch.Size([4, 64, 64])
clap.model.audio_branch.layers.2.blocks.9.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.9.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.9.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.9.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.9.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.9.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.9.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.9.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.9.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.9.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.9.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.9.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.9.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.9.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.10.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.10.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.10.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.10.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.10.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.10.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.10.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.10.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.10.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.10.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.10.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.10.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.10.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.10.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.11.attn_mask 	 torch.Size([4, 64, 64])
clap.model.audio_branch.layers.2.blocks.11.norm1.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.11.norm1.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.11.attn.relative_position_bias_table 	 torch.Size([225, 16])
clap.model.audio_branch.layers.2.blocks.11.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.2.blocks.11.attn.qkv.weight 	 torch.Size([1536, 512])
clap.model.audio_branch.layers.2.blocks.11.attn.qkv.bias 	 torch.Size([1536])
clap.model.audio_branch.layers.2.blocks.11.attn.proj.weight 	 torch.Size([512, 512])
clap.model.audio_branch.layers.2.blocks.11.attn.proj.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.11.norm2.weight 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.11.norm2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.blocks.11.mlp.fc1.weight 	 torch.Size([2048, 512])
clap.model.audio_branch.layers.2.blocks.11.mlp.fc1.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.2.blocks.11.mlp.fc2.weight 	 torch.Size([512, 2048])
clap.model.audio_branch.layers.2.blocks.11.mlp.fc2.bias 	 torch.Size([512])
clap.model.audio_branch.layers.2.downsample.reduction.weight 	 torch.Size([1024, 2048])
clap.model.audio_branch.layers.2.downsample.norm.weight 	 torch.Size([2048])
clap.model.audio_branch.layers.2.downsample.norm.bias 	 torch.Size([2048])
clap.model.audio_branch.layers.3.blocks.0.norm1.weight 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.0.norm1.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 32])
clap.model.audio_branch.layers.3.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.3.blocks.0.attn.qkv.weight 	 torch.Size([3072, 1024])
clap.model.audio_branch.layers.3.blocks.0.attn.qkv.bias 	 torch.Size([3072])
clap.model.audio_branch.layers.3.blocks.0.attn.proj.weight 	 torch.Size([1024, 1024])
clap.model.audio_branch.layers.3.blocks.0.attn.proj.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.0.norm2.weight 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.0.norm2.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.0.mlp.fc1.weight 	 torch.Size([4096, 1024])
clap.model.audio_branch.layers.3.blocks.0.mlp.fc1.bias 	 torch.Size([4096])
clap.model.audio_branch.layers.3.blocks.0.mlp.fc2.weight 	 torch.Size([1024, 4096])
clap.model.audio_branch.layers.3.blocks.0.mlp.fc2.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.1.norm1.weight 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.1.norm1.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 32])
clap.model.audio_branch.layers.3.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
clap.model.audio_branch.layers.3.blocks.1.attn.qkv.weight 	 torch.Size([3072, 1024])
clap.model.audio_branch.layers.3.blocks.1.attn.qkv.bias 	 torch.Size([3072])
clap.model.audio_branch.layers.3.blocks.1.attn.proj.weight 	 torch.Size([1024, 1024])
clap.model.audio_branch.layers.3.blocks.1.attn.proj.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.1.norm2.weight 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.1.norm2.bias 	 torch.Size([1024])
clap.model.audio_branch.layers.3.blocks.1.mlp.fc1.weight 	 torch.Size([4096, 1024])
clap.model.audio_branch.layers.3.blocks.1.mlp.fc1.bias 	 torch.Size([4096])
clap.model.audio_branch.layers.3.blocks.1.mlp.fc2.weight 	 torch.Size([1024, 4096])
clap.model.audio_branch.layers.3.blocks.1.mlp.fc2.bias 	 torch.Size([1024])
clap.model.audio_branch.norm.weight 	 torch.Size([1024])
clap.model.audio_branch.norm.bias 	 torch.Size([1024])
clap.model.audio_branch.tscam_conv.weight 	 torch.Size([527, 1024, 2, 3])
clap.model.audio_branch.tscam_conv.bias 	 torch.Size([527])
clap.model.audio_branch.head.weight 	 torch.Size([527, 527])
clap.model.audio_branch.head.bias 	 torch.Size([527])
clap.model.text_branch.embeddings.position_ids 	 torch.Size([1, 514])
clap.model.text_branch.embeddings.word_embeddings.weight 	 torch.Size([50265, 768])
clap.model.text_branch.embeddings.position_embeddings.weight 	 torch.Size([514, 768])
clap.model.text_branch.embeddings.token_type_embeddings.weight 	 torch.Size([1, 768])
clap.model.text_branch.embeddings.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.embeddings.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.0.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.0.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.0.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.0.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.0.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.0.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.0.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.0.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.1.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.1.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.1.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.1.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.1.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.1.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.1.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.1.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.2.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.2.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.2.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.2.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.2.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.2.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.2.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.2.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.3.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.3.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.3.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.3.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.3.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.3.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.3.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.3.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.4.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.4.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.4.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.4.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.4.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.4.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.4.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.4.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.5.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.5.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.5.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.5.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.5.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.5.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.5.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.5.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.6.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.6.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.6.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.6.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.6.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.6.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.6.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.6.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.7.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.7.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.7.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.7.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.7.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.7.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.7.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.7.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.8.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.8.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.8.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.8.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.8.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.8.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.8.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.8.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.9.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.9.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.9.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.9.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.9.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.9.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.9.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.9.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.10.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.10.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.10.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.10.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.10.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.10.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.10.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.10.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.attention.self.query.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.11.attention.self.query.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.attention.self.key.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.11.attention.self.key.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.attention.self.value.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.11.attention.self.value.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.attention.output.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.encoder.layer.11.attention.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.attention.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.attention.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.intermediate.dense.weight 	 torch.Size([3072, 768])
clap.model.text_branch.encoder.layer.11.intermediate.dense.bias 	 torch.Size([3072])
clap.model.text_branch.encoder.layer.11.output.dense.weight 	 torch.Size([768, 3072])
clap.model.text_branch.encoder.layer.11.output.dense.bias 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.output.LayerNorm.weight 	 torch.Size([768])
clap.model.text_branch.encoder.layer.11.output.LayerNorm.bias 	 torch.Size([768])
clap.model.text_branch.pooler.dense.weight 	 torch.Size([768, 768])
clap.model.text_branch.pooler.dense.bias 	 torch.Size([768])
clap.model.text_transform.sequential.0.weight 	 torch.Size([512, 512])
clap.model.text_transform.sequential.0.bias 	 torch.Size([512])
clap.model.text_transform.sequential.3.weight 	 torch.Size([512, 512])
clap.model.text_transform.sequential.3.bias 	 torch.Size([512])
clap.model.text_projection.0.weight 	 torch.Size([512, 768])
clap.model.text_projection.0.bias 	 torch.Size([512])
clap.model.text_projection.2.weight 	 torch.Size([512, 512])
clap.model.text_projection.2.bias 	 torch.Size([512])
clap.model.audio_transform.sequential.0.weight 	 torch.Size([512, 512])
clap.model.audio_transform.sequential.0.bias 	 torch.Size([512])
clap.model.audio_transform.sequential.3.weight 	 torch.Size([512, 512])
clap.model.audio_transform.sequential.3.bias 	 torch.Size([512])
clap.model.audio_projection.0.weight 	 torch.Size([512, 1024])
clap.model.audio_projection.0.bias 	 torch.Size([512])
clap.model.audio_projection.2.weight 	 torch.Size([512, 512])
clap.model.audio_projection.2.bias 	 torch.Size([512])
clap.mel_transform.spectrogram.window 	 torch.Size([1024])
clap.mel_transform.mel_scale.fb 	 torch.Size([513, 64])
model.diffusion_model.time_embed.0.weight 	 torch.Size([512, 128])
model.diffusion_model.time_embed.0.bias 	 torch.Size([512])
model.diffusion_model.time_embed.2.weight 	 torch.Size([512, 512])
model.diffusion_model.time_embed.2.bias 	 torch.Size([512])
model.diffusion_model.film_emb.weight 	 torch.Size([512, 512])
model.diffusion_model.film_emb.bias 	 torch.Size([512])
model.diffusion_model.input_blocks.0.0.weight 	 torch.Size([128, 16, 3, 3])
model.diffusion_model.input_blocks.0.0.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.in_layers.0.weight 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.in_layers.0.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.in_layers.2.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.input_blocks.1.0.in_layers.2.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.emb_layers.1.weight 	 torch.Size([128, 1024])
model.diffusion_model.input_blocks.1.0.emb_layers.1.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.out_layers.0.weight 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.out_layers.0.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.1.0.out_layers.3.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.input_blocks.1.0.out_layers.3.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.in_layers.0.weight 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.in_layers.0.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.in_layers.2.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.input_blocks.2.0.in_layers.2.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.emb_layers.1.weight 	 torch.Size([128, 1024])
model.diffusion_model.input_blocks.2.0.emb_layers.1.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.out_layers.0.weight 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.out_layers.0.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.2.0.out_layers.3.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.input_blocks.2.0.out_layers.3.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.3.0.op.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.input_blocks.3.0.op.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.4.0.in_layers.0.weight 	 torch.Size([128])
model.diffusion_model.input_blocks.4.0.in_layers.0.bias 	 torch.Size([128])
model.diffusion_model.input_blocks.4.0.in_layers.2.weight 	 torch.Size([256, 128, 3, 3])
model.diffusion_model.input_blocks.4.0.in_layers.2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.0.emb_layers.1.weight 	 torch.Size([256, 1024])
model.diffusion_model.input_blocks.4.0.emb_layers.1.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.0.out_layers.0.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.0.out_layers.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.0.out_layers.3.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.input_blocks.4.0.out_layers.3.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.0.skip_connection.weight 	 torch.Size([256, 128, 1, 1])
model.diffusion_model.input_blocks.4.0.skip_connection.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.norm.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.norm.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.4.1.proj_in.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.1.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.4.1.proj_out.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.norm.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.norm.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.4.2.proj_in.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.4.2.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.4.2.proj_out.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.in_layers.0.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.in_layers.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.in_layers.2.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.input_blocks.5.0.in_layers.2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.emb_layers.1.weight 	 torch.Size([256, 1024])
model.diffusion_model.input_blocks.5.0.emb_layers.1.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.out_layers.0.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.out_layers.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.0.out_layers.3.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.input_blocks.5.0.out_layers.3.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.norm.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.norm.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.5.1.proj_in.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.1.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.5.1.proj_out.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.norm.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.norm.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.5.2.proj_in.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.5.2.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.input_blocks.5.2.proj_out.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.6.0.op.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.input_blocks.6.0.op.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.7.0.in_layers.0.weight 	 torch.Size([256])
model.diffusion_model.input_blocks.7.0.in_layers.0.bias 	 torch.Size([256])
model.diffusion_model.input_blocks.7.0.in_layers.2.weight 	 torch.Size([384, 256, 3, 3])
model.diffusion_model.input_blocks.7.0.in_layers.2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.0.emb_layers.1.weight 	 torch.Size([384, 1024])
model.diffusion_model.input_blocks.7.0.emb_layers.1.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.0.out_layers.0.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.0.out_layers.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.0.out_layers.3.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.input_blocks.7.0.out_layers.3.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.0.skip_connection.weight 	 torch.Size([384, 256, 1, 1])
model.diffusion_model.input_blocks.7.0.skip_connection.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.norm.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.norm.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.7.1.proj_in.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.1.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.7.1.proj_out.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.norm.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.norm.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.7.2.proj_in.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.7.2.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.7.2.proj_out.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.in_layers.0.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.in_layers.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.in_layers.2.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.input_blocks.8.0.in_layers.2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.emb_layers.1.weight 	 torch.Size([384, 1024])
model.diffusion_model.input_blocks.8.0.emb_layers.1.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.out_layers.0.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.out_layers.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.0.out_layers.3.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.input_blocks.8.0.out_layers.3.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.norm.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.norm.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.8.1.proj_in.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.1.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.8.1.proj_out.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.norm.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.norm.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.8.2.proj_in.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.8.2.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.input_blocks.8.2.proj_out.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.9.0.op.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.input_blocks.9.0.op.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.10.0.in_layers.0.weight 	 torch.Size([384])
model.diffusion_model.input_blocks.10.0.in_layers.0.bias 	 torch.Size([384])
model.diffusion_model.input_blocks.10.0.in_layers.2.weight 	 torch.Size([640, 384, 3, 3])
model.diffusion_model.input_blocks.10.0.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.0.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.input_blocks.10.0.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.0.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.0.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.0.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.input_blocks.10.0.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.0.skip_connection.weight 	 torch.Size([640, 384, 1, 1])
model.diffusion_model.input_blocks.10.0.skip_connection.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.norm.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.norm.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.10.1.proj_in.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.1.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.10.1.proj_out.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.norm.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.norm.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.10.2.proj_in.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.10.2.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.10.2.proj_out.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.in_layers.0.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.in_layers.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.in_layers.2.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.input_blocks.11.0.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.input_blocks.11.0.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.0.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.input_blocks.11.0.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.norm.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.norm.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.11.1.proj_in.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.1.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.11.1.proj_out.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.norm.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.norm.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.11.2.proj_in.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.input_blocks.11.2.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.input_blocks.11.2.proj_out.bias 	 torch.Size([640])
model.diffusion_model.middle_block.0.in_layers.0.weight 	 torch.Size([640])
model.diffusion_model.middle_block.0.in_layers.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.0.in_layers.2.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.middle_block.0.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.middle_block.0.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.middle_block.0.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.middle_block.0.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.middle_block.0.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.0.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.middle_block.0.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.norm.weight 	 torch.Size([640])
model.diffusion_model.middle_block.1.norm.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.middle_block.1.proj_in.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.middle_block.1.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.middle_block.1.proj_out.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.norm.weight 	 torch.Size([640])
model.diffusion_model.middle_block.2.norm.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.middle_block.2.proj_in.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.middle_block.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.middle_block.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.middle_block.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.middle_block.2.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.middle_block.2.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.middle_block.2.proj_out.bias 	 torch.Size([640])
model.diffusion_model.middle_block.3.in_layers.0.weight 	 torch.Size([640])
model.diffusion_model.middle_block.3.in_layers.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.3.in_layers.2.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.middle_block.3.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.middle_block.3.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.middle_block.3.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.middle_block.3.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.middle_block.3.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.middle_block.3.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.middle_block.3.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.0.in_layers.0.weight 	 torch.Size([1280])
model.diffusion_model.output_blocks.0.0.in_layers.0.bias 	 torch.Size([1280])
model.diffusion_model.output_blocks.0.0.in_layers.2.weight 	 torch.Size([640, 1280, 3, 3])
model.diffusion_model.output_blocks.0.0.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.0.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.output_blocks.0.0.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.0.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.0.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.0.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.output_blocks.0.0.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.0.skip_connection.weight 	 torch.Size([640, 1280, 1, 1])
model.diffusion_model.output_blocks.0.0.skip_connection.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.norm.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.norm.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.0.1.proj_in.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.1.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.0.1.proj_out.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.norm.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.norm.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.0.2.proj_in.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.0.2.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.0.2.proj_out.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.0.in_layers.0.weight 	 torch.Size([1280])
model.diffusion_model.output_blocks.1.0.in_layers.0.bias 	 torch.Size([1280])
model.diffusion_model.output_blocks.1.0.in_layers.2.weight 	 torch.Size([640, 1280, 3, 3])
model.diffusion_model.output_blocks.1.0.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.0.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.output_blocks.1.0.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.0.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.0.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.0.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.output_blocks.1.0.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.0.skip_connection.weight 	 torch.Size([640, 1280, 1, 1])
model.diffusion_model.output_blocks.1.0.skip_connection.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.norm.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.norm.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.1.1.proj_in.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.1.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.1.1.proj_out.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.norm.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.norm.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.1.2.proj_in.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.1.2.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.1.2.proj_out.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.0.in_layers.0.weight 	 torch.Size([1024])
model.diffusion_model.output_blocks.2.0.in_layers.0.bias 	 torch.Size([1024])
model.diffusion_model.output_blocks.2.0.in_layers.2.weight 	 torch.Size([640, 1024, 3, 3])
model.diffusion_model.output_blocks.2.0.in_layers.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.0.emb_layers.1.weight 	 torch.Size([640, 1024])
model.diffusion_model.output_blocks.2.0.emb_layers.1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.0.out_layers.0.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.0.out_layers.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.0.out_layers.3.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.output_blocks.2.0.out_layers.3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.0.skip_connection.weight 	 torch.Size([640, 1024, 1, 1])
model.diffusion_model.output_blocks.2.0.skip_connection.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.norm.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.norm.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.2.1.proj_in.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.1.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.2.1.proj_out.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.norm.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.norm.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.proj_in.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.2.2.proj_in.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([5120, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([5120])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([640, 2560])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([640, 640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.norm1.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.norm1.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.norm2.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.norm2.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.norm3.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.transformer_blocks.0.norm3.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.2.proj_out.weight 	 torch.Size([640, 640, 1, 1])
model.diffusion_model.output_blocks.2.2.proj_out.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.2.3.conv.weight 	 torch.Size([640, 640, 3, 3])
model.diffusion_model.output_blocks.2.3.conv.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.3.0.in_layers.0.weight 	 torch.Size([1024])
model.diffusion_model.output_blocks.3.0.in_layers.0.bias 	 torch.Size([1024])
model.diffusion_model.output_blocks.3.0.in_layers.2.weight 	 torch.Size([384, 1024, 3, 3])
model.diffusion_model.output_blocks.3.0.in_layers.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.0.emb_layers.1.weight 	 torch.Size([384, 1024])
model.diffusion_model.output_blocks.3.0.emb_layers.1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.0.out_layers.0.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.0.out_layers.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.0.out_layers.3.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.output_blocks.3.0.out_layers.3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.0.skip_connection.weight 	 torch.Size([384, 1024, 1, 1])
model.diffusion_model.output_blocks.3.0.skip_connection.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.norm.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.norm.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.3.1.proj_in.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.1.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.3.1.proj_out.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.norm.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.norm.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.3.2.proj_in.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.3.2.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.3.2.proj_out.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.0.in_layers.0.weight 	 torch.Size([768])
model.diffusion_model.output_blocks.4.0.in_layers.0.bias 	 torch.Size([768])
model.diffusion_model.output_blocks.4.0.in_layers.2.weight 	 torch.Size([384, 768, 3, 3])
model.diffusion_model.output_blocks.4.0.in_layers.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.0.emb_layers.1.weight 	 torch.Size([384, 1024])
model.diffusion_model.output_blocks.4.0.emb_layers.1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.0.out_layers.0.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.0.out_layers.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.0.out_layers.3.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.output_blocks.4.0.out_layers.3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.0.skip_connection.weight 	 torch.Size([384, 768, 1, 1])
model.diffusion_model.output_blocks.4.0.skip_connection.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.norm.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.norm.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.4.1.proj_in.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.1.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.4.1.proj_out.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.norm.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.norm.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.4.2.proj_in.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.4.2.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.4.2.proj_out.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.0.in_layers.0.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.5.0.in_layers.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.5.0.in_layers.2.weight 	 torch.Size([384, 640, 3, 3])
model.diffusion_model.output_blocks.5.0.in_layers.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.0.emb_layers.1.weight 	 torch.Size([384, 1024])
model.diffusion_model.output_blocks.5.0.emb_layers.1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.0.out_layers.0.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.0.out_layers.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.0.out_layers.3.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.output_blocks.5.0.out_layers.3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.0.skip_connection.weight 	 torch.Size([384, 640, 1, 1])
model.diffusion_model.output_blocks.5.0.skip_connection.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.norm.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.norm.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.5.1.proj_in.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.1.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.5.1.proj_out.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.norm.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.norm.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.proj_in.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.5.2.proj_in.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([3072, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([3072])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([384, 1536])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([384, 384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.norm1.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.norm1.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.norm2.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.norm2.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.norm3.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.transformer_blocks.0.norm3.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.2.proj_out.weight 	 torch.Size([384, 384, 1, 1])
model.diffusion_model.output_blocks.5.2.proj_out.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.5.3.conv.weight 	 torch.Size([384, 384, 3, 3])
model.diffusion_model.output_blocks.5.3.conv.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.6.0.in_layers.0.weight 	 torch.Size([640])
model.diffusion_model.output_blocks.6.0.in_layers.0.bias 	 torch.Size([640])
model.diffusion_model.output_blocks.6.0.in_layers.2.weight 	 torch.Size([256, 640, 3, 3])
model.diffusion_model.output_blocks.6.0.in_layers.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.0.emb_layers.1.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.6.0.emb_layers.1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.0.out_layers.0.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.0.out_layers.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.0.out_layers.3.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.output_blocks.6.0.out_layers.3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.0.skip_connection.weight 	 torch.Size([256, 640, 1, 1])
model.diffusion_model.output_blocks.6.0.skip_connection.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.norm.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.norm.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.6.1.proj_in.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.1.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.6.1.proj_out.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.norm.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.norm.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.6.2.proj_in.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.6.2.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.6.2.proj_out.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.0.in_layers.0.weight 	 torch.Size([512])
model.diffusion_model.output_blocks.7.0.in_layers.0.bias 	 torch.Size([512])
model.diffusion_model.output_blocks.7.0.in_layers.2.weight 	 torch.Size([256, 512, 3, 3])
model.diffusion_model.output_blocks.7.0.in_layers.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.0.emb_layers.1.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.7.0.emb_layers.1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.0.out_layers.0.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.0.out_layers.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.0.out_layers.3.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.output_blocks.7.0.out_layers.3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.0.skip_connection.weight 	 torch.Size([256, 512, 1, 1])
model.diffusion_model.output_blocks.7.0.skip_connection.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.norm.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.norm.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.7.1.proj_in.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.1.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.7.1.proj_out.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.norm.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.norm.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.7.2.proj_in.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.7.2.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.7.2.proj_out.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.0.in_layers.0.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.8.0.in_layers.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.8.0.in_layers.2.weight 	 torch.Size([256, 384, 3, 3])
model.diffusion_model.output_blocks.8.0.in_layers.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.0.emb_layers.1.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.8.0.emb_layers.1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.0.out_layers.0.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.0.out_layers.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.0.out_layers.3.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.output_blocks.8.0.out_layers.3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.0.skip_connection.weight 	 torch.Size([256, 384, 1, 1])
model.diffusion_model.output_blocks.8.0.skip_connection.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.norm.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.norm.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.8.1.proj_in.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.1.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.8.1.proj_out.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.norm.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.norm.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.proj_in.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.8.2.proj_in.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn1.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn1.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn1.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn1.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn1.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.ff.net.0.proj.weight 	 torch.Size([2048, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.ff.net.0.proj.bias 	 torch.Size([2048])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.ff.net.2.weight 	 torch.Size([256, 1024])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.ff.net.2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn2.to_q.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn2.to_k.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn2.to_v.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn2.to_out.0.weight 	 torch.Size([256, 256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.attn2.to_out.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.norm1.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.norm1.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.norm2.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.norm2.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.norm3.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.transformer_blocks.0.norm3.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.2.proj_out.weight 	 torch.Size([256, 256, 1, 1])
model.diffusion_model.output_blocks.8.2.proj_out.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.8.3.conv.weight 	 torch.Size([256, 256, 3, 3])
model.diffusion_model.output_blocks.8.3.conv.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.9.0.in_layers.0.weight 	 torch.Size([384])
model.diffusion_model.output_blocks.9.0.in_layers.0.bias 	 torch.Size([384])
model.diffusion_model.output_blocks.9.0.in_layers.2.weight 	 torch.Size([128, 384, 3, 3])
model.diffusion_model.output_blocks.9.0.in_layers.2.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.9.0.emb_layers.1.weight 	 torch.Size([128, 1024])
model.diffusion_model.output_blocks.9.0.emb_layers.1.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.9.0.out_layers.0.weight 	 torch.Size([128])
model.diffusion_model.output_blocks.9.0.out_layers.0.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.9.0.out_layers.3.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.output_blocks.9.0.out_layers.3.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.9.0.skip_connection.weight 	 torch.Size([128, 384, 1, 1])
model.diffusion_model.output_blocks.9.0.skip_connection.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.10.0.in_layers.0.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.10.0.in_layers.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.10.0.in_layers.2.weight 	 torch.Size([128, 256, 3, 3])
model.diffusion_model.output_blocks.10.0.in_layers.2.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.10.0.emb_layers.1.weight 	 torch.Size([128, 1024])
model.diffusion_model.output_blocks.10.0.emb_layers.1.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.10.0.out_layers.0.weight 	 torch.Size([128])
model.diffusion_model.output_blocks.10.0.out_layers.0.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.10.0.out_layers.3.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.output_blocks.10.0.out_layers.3.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.10.0.skip_connection.weight 	 torch.Size([128, 256, 1, 1])
model.diffusion_model.output_blocks.10.0.skip_connection.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.11.0.in_layers.0.weight 	 torch.Size([256])
model.diffusion_model.output_blocks.11.0.in_layers.0.bias 	 torch.Size([256])
model.diffusion_model.output_blocks.11.0.in_layers.2.weight 	 torch.Size([128, 256, 3, 3])
model.diffusion_model.output_blocks.11.0.in_layers.2.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.11.0.emb_layers.1.weight 	 torch.Size([128, 1024])
model.diffusion_model.output_blocks.11.0.emb_layers.1.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.11.0.out_layers.0.weight 	 torch.Size([128])
model.diffusion_model.output_blocks.11.0.out_layers.0.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.11.0.out_layers.3.weight 	 torch.Size([128, 128, 3, 3])
model.diffusion_model.output_blocks.11.0.out_layers.3.bias 	 torch.Size([128])
model.diffusion_model.output_blocks.11.0.skip_connection.weight 	 torch.Size([128, 256, 1, 1])
model.diffusion_model.output_blocks.11.0.skip_connection.bias 	 torch.Size([128])
model.diffusion_model.out.0.weight 	 torch.Size([128])
model.diffusion_model.out.0.bias 	 torch.Size([128])
model.diffusion_model.out.2.weight 	 torch.Size([16, 128, 3, 3])
model.diffusion_model.out.2.bias 	 torch.Size([16])
model_ema.decay 	 torch.Size([])
model_ema.num_updates 	 torch.Size([])
model_ema.diffusion_modeltime_embed0weight 	 torch.Size([512, 128])
model_ema.diffusion_modeltime_embed0bias 	 torch.Size([512])
model_ema.diffusion_modeltime_embed2weight 	 torch.Size([512, 512])
model_ema.diffusion_modeltime_embed2bias 	 torch.Size([512])
model_ema.diffusion_modelfilm_embweight 	 torch.Size([512, 512])
model_ema.diffusion_modelfilm_embbias 	 torch.Size([512])
model_ema.diffusion_modelinput_blocks00weight 	 torch.Size([128, 16, 3, 3])
model_ema.diffusion_modelinput_blocks00bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10in_layers0weight 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10in_layers0bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10in_layers2weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modelinput_blocks10in_layers2bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10emb_layers1weight 	 torch.Size([128, 1024])
model_ema.diffusion_modelinput_blocks10emb_layers1bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10out_layers0weight 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10out_layers0bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks10out_layers3weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modelinput_blocks10out_layers3bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20in_layers0weight 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20in_layers0bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20in_layers2weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modelinput_blocks20in_layers2bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20emb_layers1weight 	 torch.Size([128, 1024])
model_ema.diffusion_modelinput_blocks20emb_layers1bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20out_layers0weight 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20out_layers0bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks20out_layers3weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modelinput_blocks20out_layers3bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks30opweight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modelinput_blocks30opbias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks40in_layers0weight 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks40in_layers0bias 	 torch.Size([128])
model_ema.diffusion_modelinput_blocks40in_layers2weight 	 torch.Size([256, 128, 3, 3])
model_ema.diffusion_modelinput_blocks40in_layers2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks40emb_layers1weight 	 torch.Size([256, 1024])
model_ema.diffusion_modelinput_blocks40emb_layers1bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks40out_layers0weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks40out_layers0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks40out_layers3weight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modelinput_blocks40out_layers3bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks40skip_connectionweight 	 torch.Size([256, 128, 1, 1])
model_ema.diffusion_modelinput_blocks40skip_connectionbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41normweight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41normbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks41proj_inbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modelinput_blocks41transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks41proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks41proj_outbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42normweight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42normbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks42proj_inbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modelinput_blocks42transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modelinput_blocks42transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks42proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks42proj_outbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50in_layers0weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50in_layers0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50in_layers2weight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modelinput_blocks50in_layers2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50emb_layers1weight 	 torch.Size([256, 1024])
model_ema.diffusion_modelinput_blocks50emb_layers1bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50out_layers0weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50out_layers0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks50out_layers3weight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modelinput_blocks50out_layers3bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51normweight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51normbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks51proj_inbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modelinput_blocks51transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks51proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks51proj_outbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52normweight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52normbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks52proj_inbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modelinput_blocks52transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modelinput_blocks52transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks52proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modelinput_blocks52proj_outbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks60opweight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modelinput_blocks60opbias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks70in_layers0weight 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks70in_layers0bias 	 torch.Size([256])
model_ema.diffusion_modelinput_blocks70in_layers2weight 	 torch.Size([384, 256, 3, 3])
model_ema.diffusion_modelinput_blocks70in_layers2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks70emb_layers1weight 	 torch.Size([384, 1024])
model_ema.diffusion_modelinput_blocks70emb_layers1bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks70out_layers0weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks70out_layers0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks70out_layers3weight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modelinput_blocks70out_layers3bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks70skip_connectionweight 	 torch.Size([384, 256, 1, 1])
model_ema.diffusion_modelinput_blocks70skip_connectionbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71normweight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71normbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks71proj_inbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modelinput_blocks71transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks71proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks71proj_outbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72normweight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72normbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks72proj_inbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modelinput_blocks72transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modelinput_blocks72transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks72proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks72proj_outbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80in_layers0weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80in_layers0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80in_layers2weight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modelinput_blocks80in_layers2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80emb_layers1weight 	 torch.Size([384, 1024])
model_ema.diffusion_modelinput_blocks80emb_layers1bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80out_layers0weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80out_layers0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks80out_layers3weight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modelinput_blocks80out_layers3bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81normweight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81normbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks81proj_inbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modelinput_blocks81transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks81proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks81proj_outbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82normweight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82normbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks82proj_inbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modelinput_blocks82transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modelinput_blocks82transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks82proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modelinput_blocks82proj_outbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks90opweight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modelinput_blocks90opbias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks100in_layers0weight 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks100in_layers0bias 	 torch.Size([384])
model_ema.diffusion_modelinput_blocks100in_layers2weight 	 torch.Size([640, 384, 3, 3])
model_ema.diffusion_modelinput_blocks100in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks100emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modelinput_blocks100emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks100out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks100out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks100out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelinput_blocks100out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks100skip_connectionweight 	 torch.Size([640, 384, 1, 1])
model_ema.diffusion_modelinput_blocks100skip_connectionbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101normweight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101normbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks101proj_inbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modelinput_blocks101transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modelinput_blocks101transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks101proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks101proj_outbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102normweight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102normbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks102proj_inbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modelinput_blocks102transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modelinput_blocks102transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks102proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks102proj_outbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110in_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110in_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110in_layers2weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelinput_blocks110in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modelinput_blocks110emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks110out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelinput_blocks110out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111normweight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111normbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks111proj_inbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modelinput_blocks111transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modelinput_blocks111transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks111proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks111proj_outbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112normweight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112normbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks112proj_inbias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modelinput_blocks112transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modelinput_blocks112transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modelinput_blocks112proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelinput_blocks112proj_outbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0in_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0in_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0in_layers2weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelmiddle_block0in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modelmiddle_block0emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block0out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelmiddle_block0out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1normweight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1normbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelmiddle_block1proj_inbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modelmiddle_block1transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block1proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelmiddle_block1proj_outbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2normweight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2normbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelmiddle_block2proj_inbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modelmiddle_block2transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modelmiddle_block2transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block2proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modelmiddle_block2proj_outbias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3in_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3in_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3in_layers2weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelmiddle_block3in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modelmiddle_block3emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modelmiddle_block3out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modelmiddle_block3out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks00in_layers0weight 	 torch.Size([1280])
model_ema.diffusion_modeloutput_blocks00in_layers0bias 	 torch.Size([1280])
model_ema.diffusion_modeloutput_blocks00in_layers2weight 	 torch.Size([640, 1280, 3, 3])
model_ema.diffusion_modeloutput_blocks00in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks00emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modeloutput_blocks00emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks00out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks00out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks00out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modeloutput_blocks00out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks00skip_connectionweight 	 torch.Size([640, 1280, 1, 1])
model_ema.diffusion_modeloutput_blocks00skip_connectionbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01normweight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01normbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks01proj_inbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks01proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks01proj_outbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02normweight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02normbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks02proj_inbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks02proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks02proj_outbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks10in_layers0weight 	 torch.Size([1280])
model_ema.diffusion_modeloutput_blocks10in_layers0bias 	 torch.Size([1280])
model_ema.diffusion_modeloutput_blocks10in_layers2weight 	 torch.Size([640, 1280, 3, 3])
model_ema.diffusion_modeloutput_blocks10in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks10emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modeloutput_blocks10emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks10out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks10out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks10out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modeloutput_blocks10out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks10skip_connectionweight 	 torch.Size([640, 1280, 1, 1])
model_ema.diffusion_modeloutput_blocks10skip_connectionbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11normweight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11normbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks11proj_inbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks11proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks11proj_outbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12normweight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12normbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks12proj_inbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks12proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks12proj_outbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks20in_layers0weight 	 torch.Size([1024])
model_ema.diffusion_modeloutput_blocks20in_layers0bias 	 torch.Size([1024])
model_ema.diffusion_modeloutput_blocks20in_layers2weight 	 torch.Size([640, 1024, 3, 3])
model_ema.diffusion_modeloutput_blocks20in_layers2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks20emb_layers1weight 	 torch.Size([640, 1024])
model_ema.diffusion_modeloutput_blocks20emb_layers1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks20out_layers0weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks20out_layers0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks20out_layers3weight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modeloutput_blocks20out_layers3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks20skip_connectionweight 	 torch.Size([640, 1024, 1, 1])
model_ema.diffusion_modeloutput_blocks20skip_connectionbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21normweight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21normbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks21proj_inbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks21proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks21proj_outbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22normweight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22normbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22proj_inweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks22proj_inbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn1to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn1to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn1to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn1to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn1to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0ffnet0projweight 	 torch.Size([5120, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0ffnet0projbias 	 torch.Size([5120])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0ffnet2weight 	 torch.Size([640, 2560])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0ffnet2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn2to_qweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn2to_kweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn2to_vweight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn2to_out0weight 	 torch.Size([640, 640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0attn2to_out0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0norm1weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0norm1bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0norm2weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0norm2bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0norm3weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22transformer_blocks0norm3bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks22proj_outweight 	 torch.Size([640, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks22proj_outbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks23convweight 	 torch.Size([640, 640, 3, 3])
model_ema.diffusion_modeloutput_blocks23convbias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks30in_layers0weight 	 torch.Size([1024])
model_ema.diffusion_modeloutput_blocks30in_layers0bias 	 torch.Size([1024])
model_ema.diffusion_modeloutput_blocks30in_layers2weight 	 torch.Size([384, 1024, 3, 3])
model_ema.diffusion_modeloutput_blocks30in_layers2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks30emb_layers1weight 	 torch.Size([384, 1024])
model_ema.diffusion_modeloutput_blocks30emb_layers1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks30out_layers0weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks30out_layers0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks30out_layers3weight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modeloutput_blocks30out_layers3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks30skip_connectionweight 	 torch.Size([384, 1024, 1, 1])
model_ema.diffusion_modeloutput_blocks30skip_connectionbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31normweight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31normbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks31proj_inbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks31proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks31proj_outbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32normweight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32normbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks32proj_inbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks32proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks32proj_outbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks40in_layers0weight 	 torch.Size([768])
model_ema.diffusion_modeloutput_blocks40in_layers0bias 	 torch.Size([768])
model_ema.diffusion_modeloutput_blocks40in_layers2weight 	 torch.Size([384, 768, 3, 3])
model_ema.diffusion_modeloutput_blocks40in_layers2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks40emb_layers1weight 	 torch.Size([384, 1024])
model_ema.diffusion_modeloutput_blocks40emb_layers1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks40out_layers0weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks40out_layers0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks40out_layers3weight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modeloutput_blocks40out_layers3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks40skip_connectionweight 	 torch.Size([384, 768, 1, 1])
model_ema.diffusion_modeloutput_blocks40skip_connectionbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41normweight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41normbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks41proj_inbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks41proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks41proj_outbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42normweight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42normbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks42proj_inbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks42proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks42proj_outbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks50in_layers0weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks50in_layers0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks50in_layers2weight 	 torch.Size([384, 640, 3, 3])
model_ema.diffusion_modeloutput_blocks50in_layers2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks50emb_layers1weight 	 torch.Size([384, 1024])
model_ema.diffusion_modeloutput_blocks50emb_layers1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks50out_layers0weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks50out_layers0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks50out_layers3weight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modeloutput_blocks50out_layers3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks50skip_connectionweight 	 torch.Size([384, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks50skip_connectionbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51normweight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51normbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks51proj_inbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks51proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks51proj_outbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52normweight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52normbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52proj_inweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks52proj_inbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn1to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn1to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn1to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn1to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn1to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0ffnet0projweight 	 torch.Size([3072, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0ffnet0projbias 	 torch.Size([3072])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0ffnet2weight 	 torch.Size([384, 1536])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0ffnet2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn2to_qweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn2to_kweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn2to_vweight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn2to_out0weight 	 torch.Size([384, 384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0attn2to_out0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0norm1weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0norm1bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0norm2weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0norm2bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0norm3weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52transformer_blocks0norm3bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks52proj_outweight 	 torch.Size([384, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks52proj_outbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks53convweight 	 torch.Size([384, 384, 3, 3])
model_ema.diffusion_modeloutput_blocks53convbias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks60in_layers0weight 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks60in_layers0bias 	 torch.Size([640])
model_ema.diffusion_modeloutput_blocks60in_layers2weight 	 torch.Size([256, 640, 3, 3])
model_ema.diffusion_modeloutput_blocks60in_layers2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks60emb_layers1weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks60emb_layers1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks60out_layers0weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks60out_layers0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks60out_layers3weight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modeloutput_blocks60out_layers3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks60skip_connectionweight 	 torch.Size([256, 640, 1, 1])
model_ema.diffusion_modeloutput_blocks60skip_connectionbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61normweight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61normbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks61proj_inbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks61proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks61proj_outbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62normweight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62normbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks62proj_inbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks62proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks62proj_outbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks70in_layers0weight 	 torch.Size([512])
model_ema.diffusion_modeloutput_blocks70in_layers0bias 	 torch.Size([512])
model_ema.diffusion_modeloutput_blocks70in_layers2weight 	 torch.Size([256, 512, 3, 3])
model_ema.diffusion_modeloutput_blocks70in_layers2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks70emb_layers1weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks70emb_layers1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks70out_layers0weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks70out_layers0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks70out_layers3weight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modeloutput_blocks70out_layers3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks70skip_connectionweight 	 torch.Size([256, 512, 1, 1])
model_ema.diffusion_modeloutput_blocks70skip_connectionbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71normweight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71normbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks71proj_inbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks71proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks71proj_outbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72normweight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72normbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks72proj_inbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks72proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks72proj_outbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks80in_layers0weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks80in_layers0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks80in_layers2weight 	 torch.Size([256, 384, 3, 3])
model_ema.diffusion_modeloutput_blocks80in_layers2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks80emb_layers1weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks80emb_layers1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks80out_layers0weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks80out_layers0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks80out_layers3weight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modeloutput_blocks80out_layers3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks80skip_connectionweight 	 torch.Size([256, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks80skip_connectionbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81normweight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81normbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks81proj_inbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks81proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks81proj_outbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82normweight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82normbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82proj_inweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks82proj_inbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn1to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn1to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn1to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn1to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn1to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0ffnet0projweight 	 torch.Size([2048, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0ffnet0projbias 	 torch.Size([2048])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0ffnet2weight 	 torch.Size([256, 1024])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0ffnet2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn2to_qweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn2to_kweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn2to_vweight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn2to_out0weight 	 torch.Size([256, 256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0attn2to_out0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0norm1weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0norm1bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0norm2weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0norm2bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0norm3weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82transformer_blocks0norm3bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks82proj_outweight 	 torch.Size([256, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks82proj_outbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks83convweight 	 torch.Size([256, 256, 3, 3])
model_ema.diffusion_modeloutput_blocks83convbias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks90in_layers0weight 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks90in_layers0bias 	 torch.Size([384])
model_ema.diffusion_modeloutput_blocks90in_layers2weight 	 torch.Size([128, 384, 3, 3])
model_ema.diffusion_modeloutput_blocks90in_layers2bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks90emb_layers1weight 	 torch.Size([128, 1024])
model_ema.diffusion_modeloutput_blocks90emb_layers1bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks90out_layers0weight 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks90out_layers0bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks90out_layers3weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modeloutput_blocks90out_layers3bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks90skip_connectionweight 	 torch.Size([128, 384, 1, 1])
model_ema.diffusion_modeloutput_blocks90skip_connectionbias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks100in_layers0weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks100in_layers0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks100in_layers2weight 	 torch.Size([128, 256, 3, 3])
model_ema.diffusion_modeloutput_blocks100in_layers2bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks100emb_layers1weight 	 torch.Size([128, 1024])
model_ema.diffusion_modeloutput_blocks100emb_layers1bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks100out_layers0weight 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks100out_layers0bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks100out_layers3weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modeloutput_blocks100out_layers3bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks100skip_connectionweight 	 torch.Size([128, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks100skip_connectionbias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks110in_layers0weight 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks110in_layers0bias 	 torch.Size([256])
model_ema.diffusion_modeloutput_blocks110in_layers2weight 	 torch.Size([128, 256, 3, 3])
model_ema.diffusion_modeloutput_blocks110in_layers2bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks110emb_layers1weight 	 torch.Size([128, 1024])
model_ema.diffusion_modeloutput_blocks110emb_layers1bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks110out_layers0weight 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks110out_layers0bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks110out_layers3weight 	 torch.Size([128, 128, 3, 3])
model_ema.diffusion_modeloutput_blocks110out_layers3bias 	 torch.Size([128])
model_ema.diffusion_modeloutput_blocks110skip_connectionweight 	 torch.Size([128, 256, 1, 1])
model_ema.diffusion_modeloutput_blocks110skip_connectionbias 	 torch.Size([128])
model_ema.diffusion_modelout0weight 	 torch.Size([128])
model_ema.diffusion_modelout0bias 	 torch.Size([128])
model_ema.diffusion_modelout2weight 	 torch.Size([16, 128, 3, 3])
model_ema.diffusion_modelout2bias 	 torch.Size([16])
first_stage_model.encoder.conv_in.weight 	 torch.Size([128, 1, 3, 3])
first_stage_model.encoder.conv_in.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.0.norm1.weight 	 torch.Size([128])
first_stage_model.encoder.down.0.block.0.norm1.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.0.conv1.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.encoder.down.0.block.0.conv1.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.0.norm2.weight 	 torch.Size([128])
first_stage_model.encoder.down.0.block.0.norm2.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.0.conv2.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.encoder.down.0.block.0.conv2.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.1.norm1.weight 	 torch.Size([128])
first_stage_model.encoder.down.0.block.1.norm1.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.1.conv1.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.encoder.down.0.block.1.conv1.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.1.norm2.weight 	 torch.Size([128])
first_stage_model.encoder.down.0.block.1.norm2.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.block.1.conv2.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.encoder.down.0.block.1.conv2.bias 	 torch.Size([128])
first_stage_model.encoder.down.0.downsample.conv.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.encoder.down.0.downsample.conv.bias 	 torch.Size([128])
first_stage_model.encoder.down.1.block.0.norm1.weight 	 torch.Size([128])
first_stage_model.encoder.down.1.block.0.norm1.bias 	 torch.Size([128])
first_stage_model.encoder.down.1.block.0.conv1.weight 	 torch.Size([256, 128, 3, 3])
first_stage_model.encoder.down.1.block.0.conv1.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.0.norm2.weight 	 torch.Size([256])
first_stage_model.encoder.down.1.block.0.norm2.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.0.conv2.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.encoder.down.1.block.0.conv2.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.0.nin_shortcut.weight 	 torch.Size([256, 128, 1, 1])
first_stage_model.encoder.down.1.block.0.nin_shortcut.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.1.norm1.weight 	 torch.Size([256])
first_stage_model.encoder.down.1.block.1.norm1.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.1.conv1.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.encoder.down.1.block.1.conv1.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.1.norm2.weight 	 torch.Size([256])
first_stage_model.encoder.down.1.block.1.norm2.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.block.1.conv2.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.encoder.down.1.block.1.conv2.bias 	 torch.Size([256])
first_stage_model.encoder.down.1.downsample.conv.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.encoder.down.1.downsample.conv.bias 	 torch.Size([256])
first_stage_model.encoder.down.2.block.0.norm1.weight 	 torch.Size([256])
first_stage_model.encoder.down.2.block.0.norm1.bias 	 torch.Size([256])
first_stage_model.encoder.down.2.block.0.conv1.weight 	 torch.Size([512, 256, 3, 3])
first_stage_model.encoder.down.2.block.0.conv1.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.0.norm2.weight 	 torch.Size([512])
first_stage_model.encoder.down.2.block.0.norm2.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.0.conv2.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.encoder.down.2.block.0.conv2.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.0.nin_shortcut.weight 	 torch.Size([512, 256, 1, 1])
first_stage_model.encoder.down.2.block.0.nin_shortcut.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.1.norm1.weight 	 torch.Size([512])
first_stage_model.encoder.down.2.block.1.norm1.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.1.conv1.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.encoder.down.2.block.1.conv1.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.1.norm2.weight 	 torch.Size([512])
first_stage_model.encoder.down.2.block.1.norm2.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.block.1.conv2.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.encoder.down.2.block.1.conv2.bias 	 torch.Size([512])
first_stage_model.encoder.down.2.downsample.conv.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.encoder.down.2.downsample.conv.bias 	 torch.Size([512])
first_stage_model.encoder.down.3.block.0.norm1.weight 	 torch.Size([512])
first_stage_model.encoder.down.3.block.0.norm1.bias 	 torch.Size([512])
first_stage_model.encoder.down.3.block.0.conv1.weight 	 torch.Size([1024, 512, 3, 3])
first_stage_model.encoder.down.3.block.0.conv1.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.0.norm2.weight 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.0.norm2.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.0.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.down.3.block.0.conv2.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.0.nin_shortcut.weight 	 torch.Size([1024, 512, 1, 1])
first_stage_model.encoder.down.3.block.0.nin_shortcut.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.1.norm1.weight 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.1.norm1.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.1.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.down.3.block.1.conv1.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.1.norm2.weight 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.1.norm2.bias 	 torch.Size([1024])
first_stage_model.encoder.down.3.block.1.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.down.3.block.1.conv2.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_1.norm1.weight 	 torch.Size([1024])
first_stage_model.encoder.mid.block_1.norm1.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_1.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.mid.block_1.conv1.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_1.norm2.weight 	 torch.Size([1024])
first_stage_model.encoder.mid.block_1.norm2.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_1.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.mid.block_1.conv2.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.attn_1.norm.weight 	 torch.Size([1024])
first_stage_model.encoder.mid.attn_1.norm.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.attn_1.q.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.encoder.mid.attn_1.q.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.attn_1.k.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.encoder.mid.attn_1.k.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.attn_1.v.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.encoder.mid.attn_1.v.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.attn_1.proj_out.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.encoder.mid.attn_1.proj_out.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_2.norm1.weight 	 torch.Size([1024])
first_stage_model.encoder.mid.block_2.norm1.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_2.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.mid.block_2.conv1.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_2.norm2.weight 	 torch.Size([1024])
first_stage_model.encoder.mid.block_2.norm2.bias 	 torch.Size([1024])
first_stage_model.encoder.mid.block_2.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.encoder.mid.block_2.conv2.bias 	 torch.Size([1024])
first_stage_model.encoder.norm_out.weight 	 torch.Size([1024])
first_stage_model.encoder.norm_out.bias 	 torch.Size([1024])
first_stage_model.encoder.conv_out.weight 	 torch.Size([32, 1024, 3, 3])
first_stage_model.encoder.conv_out.bias 	 torch.Size([32])
first_stage_model.decoder.conv_in.weight 	 torch.Size([1024, 16, 3, 3])
first_stage_model.decoder.conv_in.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_1.norm1.weight 	 torch.Size([1024])
first_stage_model.decoder.mid.block_1.norm1.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_1.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.mid.block_1.conv1.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_1.norm2.weight 	 torch.Size([1024])
first_stage_model.decoder.mid.block_1.norm2.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_1.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.mid.block_1.conv2.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.attn_1.norm.weight 	 torch.Size([1024])
first_stage_model.decoder.mid.attn_1.norm.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.attn_1.q.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.decoder.mid.attn_1.q.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.attn_1.k.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.decoder.mid.attn_1.k.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.attn_1.v.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.decoder.mid.attn_1.v.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.attn_1.proj_out.weight 	 torch.Size([1024, 1024, 1, 1])
first_stage_model.decoder.mid.attn_1.proj_out.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_2.norm1.weight 	 torch.Size([1024])
first_stage_model.decoder.mid.block_2.norm1.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_2.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.mid.block_2.conv1.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_2.norm2.weight 	 torch.Size([1024])
first_stage_model.decoder.mid.block_2.norm2.bias 	 torch.Size([1024])
first_stage_model.decoder.mid.block_2.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.mid.block_2.conv2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.0.block.0.norm1.weight 	 torch.Size([256])
first_stage_model.decoder.up.0.block.0.norm1.bias 	 torch.Size([256])
first_stage_model.decoder.up.0.block.0.conv1.weight 	 torch.Size([128, 256, 3, 3])
first_stage_model.decoder.up.0.block.0.conv1.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.0.norm2.weight 	 torch.Size([128])
first_stage_model.decoder.up.0.block.0.norm2.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.0.conv2.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.decoder.up.0.block.0.conv2.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.0.nin_shortcut.weight 	 torch.Size([128, 256, 1, 1])
first_stage_model.decoder.up.0.block.0.nin_shortcut.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.1.norm1.weight 	 torch.Size([128])
first_stage_model.decoder.up.0.block.1.norm1.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.1.conv1.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.decoder.up.0.block.1.conv1.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.1.norm2.weight 	 torch.Size([128])
first_stage_model.decoder.up.0.block.1.norm2.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.1.conv2.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.decoder.up.0.block.1.conv2.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.2.norm1.weight 	 torch.Size([128])
first_stage_model.decoder.up.0.block.2.norm1.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.2.conv1.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.decoder.up.0.block.2.conv1.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.2.norm2.weight 	 torch.Size([128])
first_stage_model.decoder.up.0.block.2.norm2.bias 	 torch.Size([128])
first_stage_model.decoder.up.0.block.2.conv2.weight 	 torch.Size([128, 128, 3, 3])
first_stage_model.decoder.up.0.block.2.conv2.bias 	 torch.Size([128])
first_stage_model.decoder.up.1.block.0.norm1.weight 	 torch.Size([512])
first_stage_model.decoder.up.1.block.0.norm1.bias 	 torch.Size([512])
first_stage_model.decoder.up.1.block.0.conv1.weight 	 torch.Size([256, 512, 3, 3])
first_stage_model.decoder.up.1.block.0.conv1.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.0.norm2.weight 	 torch.Size([256])
first_stage_model.decoder.up.1.block.0.norm2.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.0.conv2.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.decoder.up.1.block.0.conv2.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.0.nin_shortcut.weight 	 torch.Size([256, 512, 1, 1])
first_stage_model.decoder.up.1.block.0.nin_shortcut.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.1.norm1.weight 	 torch.Size([256])
first_stage_model.decoder.up.1.block.1.norm1.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.1.conv1.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.decoder.up.1.block.1.conv1.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.1.norm2.weight 	 torch.Size([256])
first_stage_model.decoder.up.1.block.1.norm2.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.1.conv2.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.decoder.up.1.block.1.conv2.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.2.norm1.weight 	 torch.Size([256])
first_stage_model.decoder.up.1.block.2.norm1.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.2.conv1.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.decoder.up.1.block.2.conv1.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.2.norm2.weight 	 torch.Size([256])
first_stage_model.decoder.up.1.block.2.norm2.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.block.2.conv2.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.decoder.up.1.block.2.conv2.bias 	 torch.Size([256])
first_stage_model.decoder.up.1.upsample.conv.weight 	 torch.Size([256, 256, 3, 3])
first_stage_model.decoder.up.1.upsample.conv.bias 	 torch.Size([256])
first_stage_model.decoder.up.2.block.0.norm1.weight 	 torch.Size([1024])
first_stage_model.decoder.up.2.block.0.norm1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.2.block.0.conv1.weight 	 torch.Size([512, 1024, 3, 3])
first_stage_model.decoder.up.2.block.0.conv1.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.0.norm2.weight 	 torch.Size([512])
first_stage_model.decoder.up.2.block.0.norm2.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.0.conv2.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.decoder.up.2.block.0.conv2.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.0.nin_shortcut.weight 	 torch.Size([512, 1024, 1, 1])
first_stage_model.decoder.up.2.block.0.nin_shortcut.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.1.norm1.weight 	 torch.Size([512])
first_stage_model.decoder.up.2.block.1.norm1.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.1.conv1.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.decoder.up.2.block.1.conv1.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.1.norm2.weight 	 torch.Size([512])
first_stage_model.decoder.up.2.block.1.norm2.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.1.conv2.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.decoder.up.2.block.1.conv2.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.2.norm1.weight 	 torch.Size([512])
first_stage_model.decoder.up.2.block.2.norm1.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.2.conv1.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.decoder.up.2.block.2.conv1.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.2.norm2.weight 	 torch.Size([512])
first_stage_model.decoder.up.2.block.2.norm2.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.block.2.conv2.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.decoder.up.2.block.2.conv2.bias 	 torch.Size([512])
first_stage_model.decoder.up.2.upsample.conv.weight 	 torch.Size([512, 512, 3, 3])
first_stage_model.decoder.up.2.upsample.conv.bias 	 torch.Size([512])
first_stage_model.decoder.up.3.block.0.norm1.weight 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.0.norm1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.0.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.block.0.conv1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.0.norm2.weight 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.0.norm2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.0.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.block.0.conv2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.1.norm1.weight 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.1.norm1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.1.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.block.1.conv1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.1.norm2.weight 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.1.norm2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.1.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.block.1.conv2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.2.norm1.weight 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.2.norm1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.2.conv1.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.block.2.conv1.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.2.norm2.weight 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.2.norm2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.block.2.conv2.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.block.2.conv2.bias 	 torch.Size([1024])
first_stage_model.decoder.up.3.upsample.conv.weight 	 torch.Size([1024, 1024, 3, 3])
first_stage_model.decoder.up.3.upsample.conv.bias 	 torch.Size([1024])
first_stage_model.decoder.norm_out.weight 	 torch.Size([128])
first_stage_model.decoder.norm_out.bias 	 torch.Size([128])
first_stage_model.decoder.conv_out.weight 	 torch.Size([1, 128, 3, 3])
first_stage_model.decoder.conv_out.bias 	 torch.Size([1])
first_stage_model.quant_conv.weight 	 torch.Size([32, 32, 1, 1])
first_stage_model.quant_conv.bias 	 torch.Size([32])
first_stage_model.post_quant_conv.weight 	 torch.Size([16, 16, 1, 1])
first_stage_model.post_quant_conv.bias 	 torch.Size([16])
first_stage_model.vocoder.conv_pre.bias 	 torch.Size([1536])
first_stage_model.vocoder.conv_pre.weight 	 torch.Size([1536, 256, 7])
first_stage_model.vocoder.ups.0.bias 	 torch.Size([768])
first_stage_model.vocoder.ups.0.weight 	 torch.Size([1536, 768, 12])
first_stage_model.vocoder.ups.1.bias 	 torch.Size([384])
first_stage_model.vocoder.ups.1.weight 	 torch.Size([768, 384, 10])
first_stage_model.vocoder.ups.2.bias 	 torch.Size([192])
first_stage_model.vocoder.ups.2.weight 	 torch.Size([384, 192, 8])
first_stage_model.vocoder.ups.3.bias 	 torch.Size([96])
first_stage_model.vocoder.ups.3.weight 	 torch.Size([192, 96, 4])
first_stage_model.vocoder.ups.4.bias 	 torch.Size([48])
first_stage_model.vocoder.ups.4.weight 	 torch.Size([96, 48, 4])
first_stage_model.vocoder.resblocks.0.convs1.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.0.convs1.0.weight 	 torch.Size([768, 768, 3])
first_stage_model.vocoder.resblocks.0.convs1.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.0.convs1.1.weight 	 torch.Size([768, 768, 3])
first_stage_model.vocoder.resblocks.0.convs1.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.0.convs1.2.weight 	 torch.Size([768, 768, 3])
first_stage_model.vocoder.resblocks.0.convs2.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.0.convs2.0.weight 	 torch.Size([768, 768, 3])
first_stage_model.vocoder.resblocks.0.convs2.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.0.convs2.1.weight 	 torch.Size([768, 768, 3])
first_stage_model.vocoder.resblocks.0.convs2.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.0.convs2.2.weight 	 torch.Size([768, 768, 3])
first_stage_model.vocoder.resblocks.1.convs1.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.1.convs1.0.weight 	 torch.Size([768, 768, 7])
first_stage_model.vocoder.resblocks.1.convs1.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.1.convs1.1.weight 	 torch.Size([768, 768, 7])
first_stage_model.vocoder.resblocks.1.convs1.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.1.convs1.2.weight 	 torch.Size([768, 768, 7])
first_stage_model.vocoder.resblocks.1.convs2.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.1.convs2.0.weight 	 torch.Size([768, 768, 7])
first_stage_model.vocoder.resblocks.1.convs2.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.1.convs2.1.weight 	 torch.Size([768, 768, 7])
first_stage_model.vocoder.resblocks.1.convs2.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.1.convs2.2.weight 	 torch.Size([768, 768, 7])
first_stage_model.vocoder.resblocks.2.convs1.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.2.convs1.0.weight 	 torch.Size([768, 768, 11])
first_stage_model.vocoder.resblocks.2.convs1.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.2.convs1.1.weight 	 torch.Size([768, 768, 11])
first_stage_model.vocoder.resblocks.2.convs1.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.2.convs1.2.weight 	 torch.Size([768, 768, 11])
first_stage_model.vocoder.resblocks.2.convs2.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.2.convs2.0.weight 	 torch.Size([768, 768, 11])
first_stage_model.vocoder.resblocks.2.convs2.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.2.convs2.1.weight 	 torch.Size([768, 768, 11])
first_stage_model.vocoder.resblocks.2.convs2.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.2.convs2.2.weight 	 torch.Size([768, 768, 11])
first_stage_model.vocoder.resblocks.3.convs1.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.3.convs1.0.weight 	 torch.Size([768, 768, 15])
first_stage_model.vocoder.resblocks.3.convs1.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.3.convs1.1.weight 	 torch.Size([768, 768, 15])
first_stage_model.vocoder.resblocks.3.convs1.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.3.convs1.2.weight 	 torch.Size([768, 768, 15])
first_stage_model.vocoder.resblocks.3.convs2.0.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.3.convs2.0.weight 	 torch.Size([768, 768, 15])
first_stage_model.vocoder.resblocks.3.convs2.1.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.3.convs2.1.weight 	 torch.Size([768, 768, 15])
first_stage_model.vocoder.resblocks.3.convs2.2.bias 	 torch.Size([768])
first_stage_model.vocoder.resblocks.3.convs2.2.weight 	 torch.Size([768, 768, 15])
first_stage_model.vocoder.resblocks.4.convs1.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.4.convs1.0.weight 	 torch.Size([384, 384, 3])
first_stage_model.vocoder.resblocks.4.convs1.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.4.convs1.1.weight 	 torch.Size([384, 384, 3])
first_stage_model.vocoder.resblocks.4.convs1.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.4.convs1.2.weight 	 torch.Size([384, 384, 3])
first_stage_model.vocoder.resblocks.4.convs2.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.4.convs2.0.weight 	 torch.Size([384, 384, 3])
first_stage_model.vocoder.resblocks.4.convs2.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.4.convs2.1.weight 	 torch.Size([384, 384, 3])
first_stage_model.vocoder.resblocks.4.convs2.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.4.convs2.2.weight 	 torch.Size([384, 384, 3])
first_stage_model.vocoder.resblocks.5.convs1.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.5.convs1.0.weight 	 torch.Size([384, 384, 7])
first_stage_model.vocoder.resblocks.5.convs1.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.5.convs1.1.weight 	 torch.Size([384, 384, 7])
first_stage_model.vocoder.resblocks.5.convs1.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.5.convs1.2.weight 	 torch.Size([384, 384, 7])
first_stage_model.vocoder.resblocks.5.convs2.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.5.convs2.0.weight 	 torch.Size([384, 384, 7])
first_stage_model.vocoder.resblocks.5.convs2.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.5.convs2.1.weight 	 torch.Size([384, 384, 7])
first_stage_model.vocoder.resblocks.5.convs2.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.5.convs2.2.weight 	 torch.Size([384, 384, 7])
first_stage_model.vocoder.resblocks.6.convs1.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.6.convs1.0.weight 	 torch.Size([384, 384, 11])
first_stage_model.vocoder.resblocks.6.convs1.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.6.convs1.1.weight 	 torch.Size([384, 384, 11])
first_stage_model.vocoder.resblocks.6.convs1.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.6.convs1.2.weight 	 torch.Size([384, 384, 11])
first_stage_model.vocoder.resblocks.6.convs2.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.6.convs2.0.weight 	 torch.Size([384, 384, 11])
first_stage_model.vocoder.resblocks.6.convs2.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.6.convs2.1.weight 	 torch.Size([384, 384, 11])
first_stage_model.vocoder.resblocks.6.convs2.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.6.convs2.2.weight 	 torch.Size([384, 384, 11])
first_stage_model.vocoder.resblocks.7.convs1.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.7.convs1.0.weight 	 torch.Size([384, 384, 15])
first_stage_model.vocoder.resblocks.7.convs1.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.7.convs1.1.weight 	 torch.Size([384, 384, 15])
first_stage_model.vocoder.resblocks.7.convs1.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.7.convs1.2.weight 	 torch.Size([384, 384, 15])
first_stage_model.vocoder.resblocks.7.convs2.0.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.7.convs2.0.weight 	 torch.Size([384, 384, 15])
first_stage_model.vocoder.resblocks.7.convs2.1.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.7.convs2.1.weight 	 torch.Size([384, 384, 15])
first_stage_model.vocoder.resblocks.7.convs2.2.bias 	 torch.Size([384])
first_stage_model.vocoder.resblocks.7.convs2.2.weight 	 torch.Size([384, 384, 15])
first_stage_model.vocoder.resblocks.8.convs1.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.8.convs1.0.weight 	 torch.Size([192, 192, 3])
first_stage_model.vocoder.resblocks.8.convs1.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.8.convs1.1.weight 	 torch.Size([192, 192, 3])
first_stage_model.vocoder.resblocks.8.convs1.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.8.convs1.2.weight 	 torch.Size([192, 192, 3])
first_stage_model.vocoder.resblocks.8.convs2.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.8.convs2.0.weight 	 torch.Size([192, 192, 3])
first_stage_model.vocoder.resblocks.8.convs2.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.8.convs2.1.weight 	 torch.Size([192, 192, 3])
first_stage_model.vocoder.resblocks.8.convs2.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.8.convs2.2.weight 	 torch.Size([192, 192, 3])
first_stage_model.vocoder.resblocks.9.convs1.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.9.convs1.0.weight 	 torch.Size([192, 192, 7])
first_stage_model.vocoder.resblocks.9.convs1.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.9.convs1.1.weight 	 torch.Size([192, 192, 7])
first_stage_model.vocoder.resblocks.9.convs1.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.9.convs1.2.weight 	 torch.Size([192, 192, 7])
first_stage_model.vocoder.resblocks.9.convs2.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.9.convs2.0.weight 	 torch.Size([192, 192, 7])
first_stage_model.vocoder.resblocks.9.convs2.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.9.convs2.1.weight 	 torch.Size([192, 192, 7])
first_stage_model.vocoder.resblocks.9.convs2.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.9.convs2.2.weight 	 torch.Size([192, 192, 7])
first_stage_model.vocoder.resblocks.10.convs1.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.10.convs1.0.weight 	 torch.Size([192, 192, 11])
first_stage_model.vocoder.resblocks.10.convs1.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.10.convs1.1.weight 	 torch.Size([192, 192, 11])
first_stage_model.vocoder.resblocks.10.convs1.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.10.convs1.2.weight 	 torch.Size([192, 192, 11])
first_stage_model.vocoder.resblocks.10.convs2.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.10.convs2.0.weight 	 torch.Size([192, 192, 11])
first_stage_model.vocoder.resblocks.10.convs2.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.10.convs2.1.weight 	 torch.Size([192, 192, 11])
first_stage_model.vocoder.resblocks.10.convs2.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.10.convs2.2.weight 	 torch.Size([192, 192, 11])
first_stage_model.vocoder.resblocks.11.convs1.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.11.convs1.0.weight 	 torch.Size([192, 192, 15])
first_stage_model.vocoder.resblocks.11.convs1.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.11.convs1.1.weight 	 torch.Size([192, 192, 15])
first_stage_model.vocoder.resblocks.11.convs1.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.11.convs1.2.weight 	 torch.Size([192, 192, 15])
first_stage_model.vocoder.resblocks.11.convs2.0.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.11.convs2.0.weight 	 torch.Size([192, 192, 15])
first_stage_model.vocoder.resblocks.11.convs2.1.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.11.convs2.1.weight 	 torch.Size([192, 192, 15])
first_stage_model.vocoder.resblocks.11.convs2.2.bias 	 torch.Size([192])
first_stage_model.vocoder.resblocks.11.convs2.2.weight 	 torch.Size([192, 192, 15])
first_stage_model.vocoder.resblocks.12.convs1.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.12.convs1.0.weight 	 torch.Size([96, 96, 3])
first_stage_model.vocoder.resblocks.12.convs1.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.12.convs1.1.weight 	 torch.Size([96, 96, 3])
first_stage_model.vocoder.resblocks.12.convs1.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.12.convs1.2.weight 	 torch.Size([96, 96, 3])
first_stage_model.vocoder.resblocks.12.convs2.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.12.convs2.0.weight 	 torch.Size([96, 96, 3])
first_stage_model.vocoder.resblocks.12.convs2.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.12.convs2.1.weight 	 torch.Size([96, 96, 3])
first_stage_model.vocoder.resblocks.12.convs2.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.12.convs2.2.weight 	 torch.Size([96, 96, 3])
first_stage_model.vocoder.resblocks.13.convs1.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.13.convs1.0.weight 	 torch.Size([96, 96, 7])
first_stage_model.vocoder.resblocks.13.convs1.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.13.convs1.1.weight 	 torch.Size([96, 96, 7])
first_stage_model.vocoder.resblocks.13.convs1.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.13.convs1.2.weight 	 torch.Size([96, 96, 7])
first_stage_model.vocoder.resblocks.13.convs2.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.13.convs2.0.weight 	 torch.Size([96, 96, 7])
first_stage_model.vocoder.resblocks.13.convs2.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.13.convs2.1.weight 	 torch.Size([96, 96, 7])
first_stage_model.vocoder.resblocks.13.convs2.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.13.convs2.2.weight 	 torch.Size([96, 96, 7])
first_stage_model.vocoder.resblocks.14.convs1.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.14.convs1.0.weight 	 torch.Size([96, 96, 11])
first_stage_model.vocoder.resblocks.14.convs1.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.14.convs1.1.weight 	 torch.Size([96, 96, 11])
first_stage_model.vocoder.resblocks.14.convs1.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.14.convs1.2.weight 	 torch.Size([96, 96, 11])
first_stage_model.vocoder.resblocks.14.convs2.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.14.convs2.0.weight 	 torch.Size([96, 96, 11])
first_stage_model.vocoder.resblocks.14.convs2.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.14.convs2.1.weight 	 torch.Size([96, 96, 11])
first_stage_model.vocoder.resblocks.14.convs2.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.14.convs2.2.weight 	 torch.Size([96, 96, 11])
first_stage_model.vocoder.resblocks.15.convs1.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.15.convs1.0.weight 	 torch.Size([96, 96, 15])
first_stage_model.vocoder.resblocks.15.convs1.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.15.convs1.1.weight 	 torch.Size([96, 96, 15])
first_stage_model.vocoder.resblocks.15.convs1.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.15.convs1.2.weight 	 torch.Size([96, 96, 15])
first_stage_model.vocoder.resblocks.15.convs2.0.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.15.convs2.0.weight 	 torch.Size([96, 96, 15])
first_stage_model.vocoder.resblocks.15.convs2.1.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.15.convs2.1.weight 	 torch.Size([96, 96, 15])
first_stage_model.vocoder.resblocks.15.convs2.2.bias 	 torch.Size([96])
first_stage_model.vocoder.resblocks.15.convs2.2.weight 	 torch.Size([96, 96, 15])
first_stage_model.vocoder.resblocks.16.convs1.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.16.convs1.0.weight 	 torch.Size([48, 48, 3])
first_stage_model.vocoder.resblocks.16.convs1.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.16.convs1.1.weight 	 torch.Size([48, 48, 3])
first_stage_model.vocoder.resblocks.16.convs1.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.16.convs1.2.weight 	 torch.Size([48, 48, 3])
first_stage_model.vocoder.resblocks.16.convs2.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.16.convs2.0.weight 	 torch.Size([48, 48, 3])
first_stage_model.vocoder.resblocks.16.convs2.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.16.convs2.1.weight 	 torch.Size([48, 48, 3])
first_stage_model.vocoder.resblocks.16.convs2.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.16.convs2.2.weight 	 torch.Size([48, 48, 3])
first_stage_model.vocoder.resblocks.17.convs1.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.17.convs1.0.weight 	 torch.Size([48, 48, 7])
first_stage_model.vocoder.resblocks.17.convs1.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.17.convs1.1.weight 	 torch.Size([48, 48, 7])
first_stage_model.vocoder.resblocks.17.convs1.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.17.convs1.2.weight 	 torch.Size([48, 48, 7])
first_stage_model.vocoder.resblocks.17.convs2.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.17.convs2.0.weight 	 torch.Size([48, 48, 7])
first_stage_model.vocoder.resblocks.17.convs2.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.17.convs2.1.weight 	 torch.Size([48, 48, 7])
first_stage_model.vocoder.resblocks.17.convs2.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.17.convs2.2.weight 	 torch.Size([48, 48, 7])
first_stage_model.vocoder.resblocks.18.convs1.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.18.convs1.0.weight 	 torch.Size([48, 48, 11])
first_stage_model.vocoder.resblocks.18.convs1.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.18.convs1.1.weight 	 torch.Size([48, 48, 11])
first_stage_model.vocoder.resblocks.18.convs1.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.18.convs1.2.weight 	 torch.Size([48, 48, 11])
first_stage_model.vocoder.resblocks.18.convs2.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.18.convs2.0.weight 	 torch.Size([48, 48, 11])
first_stage_model.vocoder.resblocks.18.convs2.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.18.convs2.1.weight 	 torch.Size([48, 48, 11])
first_stage_model.vocoder.resblocks.18.convs2.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.18.convs2.2.weight 	 torch.Size([48, 48, 11])
first_stage_model.vocoder.resblocks.19.convs1.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.19.convs1.0.weight 	 torch.Size([48, 48, 15])
first_stage_model.vocoder.resblocks.19.convs1.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.19.convs1.1.weight 	 torch.Size([48, 48, 15])
first_stage_model.vocoder.resblocks.19.convs1.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.19.convs1.2.weight 	 torch.Size([48, 48, 15])
first_stage_model.vocoder.resblocks.19.convs2.0.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.19.convs2.0.weight 	 torch.Size([48, 48, 15])
first_stage_model.vocoder.resblocks.19.convs2.1.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.19.convs2.1.weight 	 torch.Size([48, 48, 15])
first_stage_model.vocoder.resblocks.19.convs2.2.bias 	 torch.Size([48])
first_stage_model.vocoder.resblocks.19.convs2.2.weight 	 torch.Size([48, 48, 15])
first_stage_model.vocoder.conv_post.bias 	 torch.Size([1])
first_stage_model.vocoder.conv_post.weight 	 torch.Size([1, 48, 7])
cond_stage_models.0.model.logit_scale_a 	 torch.Size([])
cond_stage_models.0.model.logit_scale_t 	 torch.Size([])
cond_stage_models.0.model.audio_branch.spectrogram_extractor.stft.conv_real.weight 	 torch.Size([513, 1, 1024])
cond_stage_models.0.model.audio_branch.spectrogram_extractor.stft.conv_imag.weight 	 torch.Size([513, 1, 1024])
cond_stage_models.0.model.audio_branch.logmel_extractor.melW 	 torch.Size([513, 64])
cond_stage_models.0.model.audio_branch.bn0.weight 	 torch.Size([64])
cond_stage_models.0.model.audio_branch.bn0.bias 	 torch.Size([64])
cond_stage_models.0.model.audio_branch.bn0.running_mean 	 torch.Size([64])
cond_stage_models.0.model.audio_branch.bn0.running_var 	 torch.Size([64])
cond_stage_models.0.model.audio_branch.bn0.num_batches_tracked 	 torch.Size([])
cond_stage_models.0.model.audio_branch.patch_embed.proj.weight 	 torch.Size([128, 1, 4, 4])
cond_stage_models.0.model.audio_branch.patch_embed.proj.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.patch_embed.norm.weight 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.patch_embed.norm.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.norm1.weight 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.norm1.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 4])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.attn.qkv.weight 	 torch.Size([384, 128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.attn.qkv.bias 	 torch.Size([384])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.attn.proj.weight 	 torch.Size([128, 128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.attn.proj.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.norm2.weight 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.norm2.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.mlp.fc1.weight 	 torch.Size([512, 128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.mlp.fc1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.mlp.fc2.weight 	 torch.Size([128, 512])
cond_stage_models.0.model.audio_branch.layers.0.blocks.0.mlp.fc2.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn_mask 	 torch.Size([64, 64, 64])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.norm1.weight 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.norm1.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 4])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn.qkv.weight 	 torch.Size([384, 128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn.qkv.bias 	 torch.Size([384])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn.proj.weight 	 torch.Size([128, 128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.attn.proj.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.norm2.weight 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.norm2.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.mlp.fc1.weight 	 torch.Size([512, 128])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.mlp.fc1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.mlp.fc2.weight 	 torch.Size([128, 512])
cond_stage_models.0.model.audio_branch.layers.0.blocks.1.mlp.fc2.bias 	 torch.Size([128])
cond_stage_models.0.model.audio_branch.layers.0.downsample.reduction.weight 	 torch.Size([256, 512])
cond_stage_models.0.model.audio_branch.layers.0.downsample.norm.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.0.downsample.norm.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.norm1.weight 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.norm1.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 8])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.attn.qkv.weight 	 torch.Size([768, 256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.attn.qkv.bias 	 torch.Size([768])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.attn.proj.weight 	 torch.Size([256, 256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.attn.proj.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.norm2.weight 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.norm2.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.mlp.fc1.weight 	 torch.Size([1024, 256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.mlp.fc1.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.mlp.fc2.weight 	 torch.Size([256, 1024])
cond_stage_models.0.model.audio_branch.layers.1.blocks.0.mlp.fc2.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn_mask 	 torch.Size([16, 64, 64])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.norm1.weight 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.norm1.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 8])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn.qkv.weight 	 torch.Size([768, 256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn.qkv.bias 	 torch.Size([768])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn.proj.weight 	 torch.Size([256, 256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.attn.proj.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.norm2.weight 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.norm2.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.mlp.fc1.weight 	 torch.Size([1024, 256])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.mlp.fc1.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.mlp.fc2.weight 	 torch.Size([256, 1024])
cond_stage_models.0.model.audio_branch.layers.1.blocks.1.mlp.fc2.bias 	 torch.Size([256])
cond_stage_models.0.model.audio_branch.layers.1.downsample.reduction.weight 	 torch.Size([512, 1024])
cond_stage_models.0.model.audio_branch.layers.1.downsample.norm.weight 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.1.downsample.norm.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.0.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn_mask 	 torch.Size([4, 64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.1.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.2.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn_mask 	 torch.Size([4, 64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.3.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.4.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn_mask 	 torch.Size([4, 64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.5.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.6.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn_mask 	 torch.Size([4, 64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.7.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.8.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn_mask 	 torch.Size([4, 64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.9.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.10.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn_mask 	 torch.Size([4, 64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.norm1.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.norm1.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn.relative_position_bias_table 	 torch.Size([225, 16])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn.qkv.weight 	 torch.Size([1536, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn.qkv.bias 	 torch.Size([1536])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn.proj.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.attn.proj.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.norm2.weight 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.norm2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.mlp.fc1.weight 	 torch.Size([2048, 512])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.mlp.fc1.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.mlp.fc2.weight 	 torch.Size([512, 2048])
cond_stage_models.0.model.audio_branch.layers.2.blocks.11.mlp.fc2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_branch.layers.2.downsample.reduction.weight 	 torch.Size([1024, 2048])
cond_stage_models.0.model.audio_branch.layers.2.downsample.norm.weight 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.2.downsample.norm.bias 	 torch.Size([2048])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.norm1.weight 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.norm1.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.attn.relative_position_bias_table 	 torch.Size([225, 32])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.attn.qkv.weight 	 torch.Size([3072, 1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.attn.qkv.bias 	 torch.Size([3072])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.attn.proj.weight 	 torch.Size([1024, 1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.attn.proj.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.norm2.weight 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.norm2.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.mlp.fc1.weight 	 torch.Size([4096, 1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.mlp.fc1.bias 	 torch.Size([4096])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.mlp.fc2.weight 	 torch.Size([1024, 4096])
cond_stage_models.0.model.audio_branch.layers.3.blocks.0.mlp.fc2.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.norm1.weight 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.norm1.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.attn.relative_position_bias_table 	 torch.Size([225, 32])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.attn.relative_position_index 	 torch.Size([64, 64])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.attn.qkv.weight 	 torch.Size([3072, 1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.attn.qkv.bias 	 torch.Size([3072])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.attn.proj.weight 	 torch.Size([1024, 1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.attn.proj.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.norm2.weight 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.norm2.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.mlp.fc1.weight 	 torch.Size([4096, 1024])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.mlp.fc1.bias 	 torch.Size([4096])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.mlp.fc2.weight 	 torch.Size([1024, 4096])
cond_stage_models.0.model.audio_branch.layers.3.blocks.1.mlp.fc2.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.norm.weight 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.norm.bias 	 torch.Size([1024])
cond_stage_models.0.model.audio_branch.tscam_conv.weight 	 torch.Size([527, 1024, 2, 3])
cond_stage_models.0.model.audio_branch.tscam_conv.bias 	 torch.Size([527])
cond_stage_models.0.model.audio_branch.head.weight 	 torch.Size([527, 527])
cond_stage_models.0.model.audio_branch.head.bias 	 torch.Size([527])
cond_stage_models.0.model.text_branch.embeddings.position_ids 	 torch.Size([1, 514])
cond_stage_models.0.model.text_branch.embeddings.word_embeddings.weight 	 torch.Size([50265, 768])
cond_stage_models.0.model.text_branch.embeddings.position_embeddings.weight 	 torch.Size([514, 768])
cond_stage_models.0.model.text_branch.embeddings.token_type_embeddings.weight 	 torch.Size([1, 768])
cond_stage_models.0.model.text_branch.embeddings.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.embeddings.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.0.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.0.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.0.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.0.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.1.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.1.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.1.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.1.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.2.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.2.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.2.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.2.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.3.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.3.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.3.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.3.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.4.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.4.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.4.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.4.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.5.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.5.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.5.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.5.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.6.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.6.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.6.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.6.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.7.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.7.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.7.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.7.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.8.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.8.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.8.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.8.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.9.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.9.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.9.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.9.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.10.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.10.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.10.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.10.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.self.query.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.self.query.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.self.key.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.self.key.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.self.value.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.self.value.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.output.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.attention.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.intermediate.dense.weight 	 torch.Size([3072, 768])
cond_stage_models.0.model.text_branch.encoder.layer.11.intermediate.dense.bias 	 torch.Size([3072])
cond_stage_models.0.model.text_branch.encoder.layer.11.output.dense.weight 	 torch.Size([768, 3072])
cond_stage_models.0.model.text_branch.encoder.layer.11.output.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.output.LayerNorm.weight 	 torch.Size([768])
cond_stage_models.0.model.text_branch.encoder.layer.11.output.LayerNorm.bias 	 torch.Size([768])
cond_stage_models.0.model.text_branch.pooler.dense.weight 	 torch.Size([768, 768])
cond_stage_models.0.model.text_branch.pooler.dense.bias 	 torch.Size([768])
cond_stage_models.0.model.text_transform.sequential.0.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.text_transform.sequential.0.bias 	 torch.Size([512])
cond_stage_models.0.model.text_transform.sequential.3.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.text_transform.sequential.3.bias 	 torch.Size([512])
cond_stage_models.0.model.text_projection.0.weight 	 torch.Size([512, 768])
cond_stage_models.0.model.text_projection.0.bias 	 torch.Size([512])
cond_stage_models.0.model.text_projection.2.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.text_projection.2.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_transform.sequential.0.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_transform.sequential.0.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_transform.sequential.3.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_transform.sequential.3.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_projection.0.weight 	 torch.Size([512, 1024])
cond_stage_models.0.model.audio_projection.0.bias 	 torch.Size([512])
cond_stage_models.0.model.audio_projection.2.weight 	 torch.Size([512, 512])
cond_stage_models.0.model.audio_projection.2.bias 	 torch.Size([512])
cond_stage_models.0.mel_transform.spectrogram.window 	 torch.Size([1024])
cond_stage_models.0.mel_transform.mel_scale.fb 	 torch.Size([513, 64])
